{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "optical-purse",
   "metadata": {},
   "source": [
    "Cargar los datos del dataset de “Shakespeare”, generar el proceso necesario para generar un\n",
    "RDD o DataFrame con los siguientes Atributos (Word, Count, Group), en donde Word será\n",
    "cada palabra única en el dataset, Count la cantidad de ocurrencias, y Group una agrupación de\n",
    "3 categorías según la cantidad de palabras (p.e. “Frecuente”, “Intermedio”, “Poco Frecuente”),\n",
    "luego se debe escribir en forma de parquet en cualquier ubicación del dbfs, particionado por el\n",
    "campo Group, finalmente se debe materializar esta tabla dentro de DataWarehouse que provee\n",
    "el entorno de databricks como tabla externa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ahead-church",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "  \n",
    "from pyspark import SparkConf,SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "great-collins",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeWords(text):\n",
    "    return re.compile(r'\\W+', re.UNICODE).split(text.lower())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "indirect-aircraft",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.config(\"spark.sql.warehouse.dir\", \"file:///C:/temp\").appName(\"WordCount\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "stable-boost",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/Usuario/Documents/GitHub/Data-Science/Challenges/Oiga_spark/100-0.txt\"\n",
    "file =spark.sparkContext.textFile(\"file:///{}\".format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "weird-baking",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = file.flatMap(normalizeWords)\n",
    "wordCounts =  words.map(lambda x:(x,1)).reduceByKey(lambda x, y: x+y)\n",
    "wordCountsSorted = wordCounts.map(lambda x: (x[1], x[0])).sortByKey()\n",
    "\n",
    "results =  wordCountsSorted.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "protected-michael",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = wordCountsSorted.map(lambda x: Row(ID =int(x.split()[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "confused-rings",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = spark.createDataFrame(results).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "mechanical-manual",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.rename(columns={\"_1\":\"Count\", \"_2\":\"Word\"}).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "included-schema",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.392320\n",
       "2    0.136394\n",
       "3    0.075637\n",
       "4    0.054139\n",
       "Name: Count, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dataset.Count.value_counts() / dataset.shape[0]).head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "subtle-alignment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    10493\n",
       "2     3648\n",
       "3     2023\n",
       "4     1448\n",
       "Name: Count, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dataset.Count.value_counts()).head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungarian-aerospace",
   "metadata": {},
   "source": [
    "Se crean tres grupos para las siguientes proporciones:\n",
    "+ Frecuente: mayor o igual a 10493\n",
    "+ Intermedio: mayor o igual a 3648\n",
    "+ Poco Frecuente: menor a 3648"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "racial-walnut",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "grupos = np.where((dataset.Count >= 10493), \"Frecuente\", \"Intermedio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "decimal-aspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"Group\"]= np.where((dataset.Count < 3648), \"Poco Frecuente\", grupos)\n",
    "del grupos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "excellent-bouquet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Poco Frecuente    26704\n",
       "Intermedio           31\n",
       "Frecuente            11\n",
       "Name: Group, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.Group.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
